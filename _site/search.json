[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am curious about data and the techniques that are needed to make sense of data in this increasingly data-overwhelmed world. I explore with data visualizations on Tableau , R and make sense of it with statistical analysis using various R packages.\n\nAbove: One of my favourite images from a geospatial analysis project that I did on SAS Viya"
  },
  {
    "objectID": "Hands-On-Exercise/Hands_On_Exercise_3.html",
    "href": "Hands-On-Exercise/Hands_On_Exercise_3.html",
    "title": "Hands_On_Exercise_3",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n\nexamdata &lt;- read_csv(\"data_inclass2/Exam_data.csv\")\n\n\np &lt;- ggplot(data=examdata, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {   #&lt;&lt;\n  mean &lt;- scales::number(y, accuracy = accuracy) #&lt;&lt;\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy) #&lt;&lt;\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #&lt;&lt;\n} #&lt;&lt;\n\ngg_point &lt;- ggplot(data=examdata, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #&lt;&lt;\n                     tooltip(y, ymax))),  #&lt;&lt;\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #&lt;&lt;\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nCoordinated multi-views with ggiraph\n\nlibrary(patchwork)\n\np1 &lt;- ggplot(data=examdata, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=examdata, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #&lt;&lt;\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #&lt;&lt;\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-On-Exercise/Hands_On_Exercise_4.html",
    "href": "Hands-On-Exercise/Hands_On_Exercise_4.html",
    "title": "Hands On Exercise 04",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\ncovid19 &lt;- read_csv(\"data_inclass2/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-On-Exercise/Hands_On_Exercise_5.html",
    "href": "Hands-On-Exercise/Hands_On_Exercise_5.html",
    "title": "Hands On Exercise 05",
    "section": "",
    "text": "pacman::p_load(tidyverse, corrplot, ggstatsplot, ggcorrplot, ggtern, seriation, dendextend, heatmaply, GGally, parallelPlot)\n\n\nwine &lt;- read_csv(\"data_inclass2/wine_quality.csv\")\n\n\npairs(wine[,1:11]) #from base r graphics package that helps to create scatterplot, creates factor levels in categorical data \n\n\n\n\n\nwh &lt;- read_csv(\"data_inclass2/WHData-2018.csv\")\n\n\nrow.names(wh) &lt;- wh$Country\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)"
  },
  {
    "objectID": "Hands-On-Exercise/In-class-ex-2.html",
    "href": "Hands-On-Exercise/In-class-ex-2.html",
    "title": "In-Class_Ex-2",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n#import data\n\nexamdata &lt;- read_csv(\"data_inclass2/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\npacman::p_load(tidyverse) library(readr) library(dplyr) library(tidyr)"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-03.html",
    "href": "In-Class-Exercise/In-Class-Ex-03.html",
    "title": "In-Class Exercise 3",
    "section": "",
    "text": "Installing and loading R packages\n\npacman:: p_load(ggplot2,ggiraph, tidyverse)\n\nImporting data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") + \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-04.html",
    "href": "In-Class-Exercise/In-Class-Ex-04.html",
    "title": "In Class Exercise 4",
    "section": "",
    "text": "pacman::p_load(plotly, DT, patchwork, tidyverse, ggstatsplot, readxl, performance, parameters, see, gtsummary, crosstalk, ggdist, gganimate)\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\nAlternative way of using plotly: ggplot2\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) \n\n\n\n\n\nTwo-sample mean test (ggbetweenstats)\nStudent T-test assumes equal variance, hence the more appropriate test would be the Welsh test. Confidence interval is by default 95%.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nVisualizing Models :\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;,\n#   Radio &lt;dbl&gt;, Mistlamps &lt;dbl&gt;, Sport_Model &lt;dbl&gt;, Backseat_Divider &lt;dbl&gt;, …\n\n\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\nCan use the function asdataframe to join all the columns up together.\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\nPresenting the summary of Model with the characteristic, beta, CI and p-value.\n\ntbl_regression(model1, intercept = TRUE)\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n-2,186\n-4,093, -278\n0.025\n\n\nAge_08_04\n-119\n-125, -114\n&lt;0.001\n\n\nKM\n-0.02\n-0.03, -0.02\n&lt;0.001\n\n\nWeight\n20\n18, 21\n&lt;0.001\n\n\nGuarantee_Period\n27\n2.1, 52\n0.034\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-06.html",
    "href": "In-Class-Exercise/In-Class-Ex-06.html",
    "title": "In-Class-Ex-06",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)\n\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\nCheck the data by querying for head and there are 3 columns available.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nData preparation: Derive weekday and hour of day fields by creating a function. ymd_hms() and hour() are from the lubridate package and weekdays() is a base R function.\n\nmake_hr_wkday &lt;- function(ts, sc, tz){\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\nStep 2: deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;% \n  group_by(tz) %&gt;% \n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour = factor(\n      hour, levels = 0:23))\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\nBuild the Calendar Heatmap:\n\ngrouped &lt;- attacks %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill = n)) +\ngeom_tile(color = \"white\",\n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() + \nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") + \nlabs(x = NULL,\n     y = NULL,\n     title = \"Attacks by weekday and time of day\") + \ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6))\n\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;% \n  mutate(percent = percent(n/sum(n))) %&gt;% \n  arrange(desc(n))\n\nStep 2: preparing the tidy data frame\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;% \n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the multiple calendar heatmap by using ggplot2 package\n\nggplot(top4_attacks, \n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"white\",\n            size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() + \n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) + \n  labs(x = NULL, y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-06.html#data-preparation",
    "href": "In-Class-Exercise/In-Class-Ex-06.html#data-preparation",
    "title": "In-Class-Ex-06",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\nDerive month and year fields\n\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels = 1:12,\n                    labels = month.abb,\n                    ordered = TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\n\nExtracting target country\n\nVietnam &lt;- air %&gt;%\n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nComputing year average arrivals by month\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\nPlotting the cycle plot\n\nggplot() +\n  geom_line(data = Vietnam,\n            aes(x = year, \n            y = `Vietnam`,\n            group = month),\n            color = \"black\") + \n  geom_hline(aes(yintercept = avgvalue),\n             data=hline.data, \n             linetype = 6,\n             color = \"red\",\n             size = 0.5) + \n  facet_grid(~month) + \n  labs(axis.text.x = element_blank(),\n       title = \"visitor arrivals from Vietnam by air, Jan 20210 to Dec 2019\") + \n  xlab(\" \") + \n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-07.html",
    "href": "In-Class-Exercise/In-Class-Ex-07.html",
    "title": "In-Class-Exercise-7",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap) \n\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nRows: 306 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): NAME, ADDRESS, OUTLET TYPE\ndbl (4): POSTCODE, XCOORD, YCOORD, Gp1Gp2 Winnings\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nsgpools_sg &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"), \n                       crs = 3414) #crs is important as it indicates which country projection is being used \n\n\ntmap_mode(\"view\") \n\ntmap mode set to interactive viewing\n\n\n\ntm_shape(sgpools_sg)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\nMaking the plot proportional.\n\ntm_shape(sgpools_sg)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\nLegend for symbol sizes not available in view mode."
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-08.html",
    "href": "In-Class-Exercise/In-Class-Ex-08.html",
    "title": "In-Class-Ex-8",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n# Importing the data \n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\nglimpse(GAStech_nodes)\n\nRows: 54\nColumns: 4\n$ id         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 44, 45, 46, 8, 9, 10, 11, 12, 13, 14, …\n$ label      &lt;chr&gt; \"Mat.Bramar\", \"Anda.Ribera\", \"Rachel.Pantanal\", \"Linda.Lago…\n$ Department &lt;chr&gt; \"Administration\", \"Administration\", \"Administration\", \"Admi…\n$ Title      &lt;chr&gt; \"Assistant to CEO\", \"Assistant to CFO\", \"Assistant to CIO\",…\n\n\nWrangling Time:\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\nWrangling Attributes:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n# creating the table\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n     id label               Department     Title                                \n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# … with 1,369 more rows\n\n\n\n#Changing the active object \nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n   from    to Weekday  Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;     &lt;int&gt;\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# … with 1,366 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows\n\n\nPlotting a basic network graph\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "In-Class-Exercise/In-Class-Ex-10.html",
    "href": "In-Class-Exercise/In-Class-Ex-10.html",
    "title": "In-Class-Ex-10",
    "section": "",
    "text": "pacman::p_load(lubridate, tidyquant, ggHoriPlot,\n               timetk, ggthemes, plotly, tidyverse)\n\n\ncompany &lt;- read_csv(\"data/companySG.csv\")\nTop40 &lt;- company %&gt;% \n  slice_max(`marketcap`, n=40) %&gt;% \n  select(symbol)\n\nExtracting the daily values of the stock price of these top 40 stocks from Yahoo Finance via APIs using the tidyquant package. (Scraping)\n\nStock40_daily &lt;- Top40 %&gt;%\n  tq_get(get = \"stock.prices\", \n         from = \"2020-01-01\", \n         to = \"2022-03-31\") %&gt;%\n  group_by(symbol) %&gt;%\n  tq_transmute(select = NULL, \n               mutate_fun = to.period, \n               period  = \"days\")\n\nPlotting the Horizon Plot\n\nStock40_daily %&gt;% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(symbol~.)+\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)') \n\n\n\n\nHorizon Graph Makeover: To display the name of the stock only.\n\nStock40_daily &lt;- Stock40_daily %&gt;%\n  left_join(company) %&gt;%\n  select(1:8, 11:12)\n\n\nStock40_daily %&gt;% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(Name~.)+ #&lt;&lt;\n  geom_vline(xintercept = as.Date(\"2020-03-11\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #&lt;&lt;\n  geom_vline(xintercept = as.Date(\"2020-12-14\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #&lt;&lt;\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"),\n        strip.text.y = element_text(size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)') \n\n\n\n\nPlotting Stock Price Line Graph: ggplot methods\n\nStock40_daily %&gt;%\n  filter(symbol == \"DBSDF\") %&gt;%\n  ggplot(aes(x = date, y = close)) +\n    geom_line() +\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n         y = \"Closing Price\", x = \"\") + \n    theme_tq()\n\n\n\n\nPlotting interactive stock price line graphs\n\nselected_stocks &lt;-  Stock40_daily %&gt;%\n  filter (`symbol` == c(\"C09.SI\", \"SINGF\", \"SNGNF\", \"C52.SI\"))\n\n\np &lt;- ggplot(selected_stocks, \n            aes(x = date, y = adjusted)) + \n  scale_y_continuous() +\n  geom_line() +\n  facet_wrap(~Name, scales = \"free_y\",) +\n  theme_tq() +\n  labs(title = \"Daily stock prices of selected weak stocks\", \n       x = \"\", y = \"Adjusted Price\") + \n  theme(axis.text.x = element_text(size = 6), \n        axis.text.y = element_text(size = 6))\n\nggplotly(p)\n\n\n\n\n\nPlotting Candlestick Chart: tidyquant method\n\nend &lt;- as_date(\"2022-03-31\")\n\n\nStock40_daily %&gt;%\n  filter(symbol == \"DBSDF\") %&gt;%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\n\n\n\nPlotting candlestick chart and MA lines: tidyquant method\n\nStock40_daily %&gt;%\n  filter(symbol == \"DBSDF\") %&gt;%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n  geom_ma(color = \"darkgreen\", n = 20) +\n  geom_ma(color = \"lightgreen\", n = 5) + \n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n       subtitle = \"darkgreen = 1-day MA, lightgreen = 5-day MA\",\n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\n\n\n\nPlotting Bollinger Bands: tidyquant method\n\nStock40_daily %&gt;%\n  filter(symbol == \"DBSDF\") %&gt;% \n  ggplot(aes(x=date, y=close))+\n  geom_line(size=0.5)+\n  geom_bbands(aes(\n    high = high, low = low, close = close), \n    ma_fun = SMA, sd = 2, n = 20,\n    size = 0.75, color_ma = \"royalblue4\", \n    color_bands = \"red1\")+\n    coord_x_date(xlim = c(\"2020-02-01\", \n                          \"2022-03-31\"), \n                 expand = TRUE)+\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n         subtitle = \"dotted red lines = bollinger bands\",\n         x = \"Date\", y =\"Price\") +\ntheme(legend.position=\"none\")\n\n\n\n\nPlotting Interactive Candlesticks Chart: ggplot2 and plotly R method\n\ncandleStick_plot&lt;-function(symbol, from, to){\n  tq_get(symbol, from = from, to = to, warnings = FALSE) %&gt;% \n    mutate(greenRed=ifelse(open-close&gt;0, \"Red\", \"Green\")) %&gt;% \n    ggplot()+\n    geom_segment(\n      aes(x = date, xend=date, y =open, yend =close, colour=greenRed), \n      size=3)+\n    theme_tq()+\n    geom_segment(\n      aes(x = date, xend=date, y =high, yend =low, colour=greenRed))+\n    scale_color_manual(values=c(\"ForestGreen\",\"Red\"))+\n    ggtitle(paste0(symbol,\" (\",from,\" - \",to,\")\"))+\n    theme(legend.position =\"none\",\n          axis.title.y = element_blank(),\n          axis.title.x=element_blank(),\n          axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1),\n          plot.title= element_text(hjust=0.5))\n}\n\n\np &lt;- candleStick_plot(\"DBSDF\",\n                      from = '2022-01-01',\n                      to = today())\nggplotly(p)"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-2.html",
    "href": "Take Home Exercises/Take-Home-Exercise-2.html",
    "title": "Take-Home-Exercise-2",
    "section": "",
    "text": "The following visualization that was created by a peer was used for this critique and makeover exercise."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-2.html#critique",
    "href": "Take Home Exercises/Take-Home-Exercise-2.html#critique",
    "title": "Take-Home-Exercise-2",
    "section": "Critique",
    "text": "Critique\nClarity\n\nThe dashboard initially does not seem to give a clear intention on what the graph is about at first glance because there are three panels present which make it harder to determine which one to look first.\nEvery bar has been labelled with population values which on closer inspection, makes it harder to read and determine useful information eg. the highest and lowest population figures for both males and females for each planning area.\nThe use of a single row trellis might not give a very clear comparison view of planning areas of interest because all planning areas are placed side by side.\n\nAesthetics\n\nThe use of an additional shaded box (grey) is slightly distracting as the main point is not in these shaded boxes or areas."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-2.html#makeover",
    "href": "Take Home Exercises/Take-Home-Exercise-2.html#makeover",
    "title": "Take-Home-Exercise-2",
    "section": "Makeover",
    "text": "Makeover\nSketch of the Design Remake\nThe sketch is as follows:\n\nFinal Design\n\nIn this makeover, the trellis diagram featuring 3 X 3 panels is created instead to have a holistic view of all the 9 planning areas and an instant perception of the population distribution for both females and males. The shape and distribution of male and female population compared to other planning areas can now be easier identified.\nLabels for each value of Population of each age group was not included and instead a table of the sum of populations for Males and Females respectively for each planning area is also included.\n\nRemaking visualization via R\nLoading the packages in R and creating a subset of the desired Planning Areas to visualize.\n\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(ggpmisc)\n\n#import data \ndata &lt;- read_csv(\"CSVrespopagesextod2022.csv\")\n\n#create subset of data with 9 selected planning areas \ndata1 &lt;- data[data$PA %in% c('Ang Mo Kio', 'Bukit Merah', 'Bukit Timah', 'Hougang', 'Jurong East', 'Kallang', 'Pasir Ris','Sengkang', 'Toa Payoh'),] \nsubset(data, PA %in% c('Ang Mo Kio', 'Bukit Merah', 'Bukit Timah', 'Hougang', 'Jurong East', 'Kallang', 'Pasir Ris','Sengkang', 'Toa Payoh'))\n\n# A tibble: 28,576 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2022\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2022\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    10  2022\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    30  2022\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2022\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    50  2022\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2022\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2022\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2022\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats     0  2022\n# … with 28,566 more rows\n\n#set factor variable for AG \ndata1$AG &lt;- factor(data1$AG, levels =c(\"0_to_4\", \"5_to_9\", \"10_to_14\", \"15_to_19\", \"20_to_24\", \"25_to_29\", \"30_to_34\", \"35_to_39\", \"40_to_44\",\"45_to_49\", \"50_to_54\", \"55_to_59\", \"60_to_64\", \"65_to_69\", \"70_to_74\", \"75_to_79\", \"80_to_84\", \"85_to_89\", \"90_and_over\"))\n\n#create barchart \nm_f_pyramid &lt;- data1 %&gt;%\n  mutate(\n    Pop = case_when(\n      Sex == \"Males\" ~ -Pop, \n      TRUE ~ Pop\n    ),\n    AG = as_factor(AG)\n  )\n  \nggp&lt;- ggplot(m_f_pyramid ,\n        aes(x = Pop, \n            y = AG,\n            fill = Sex)) + \n    geom_col() + \n    scale_x_continuous(breaks = c(-150000, -10000, -5000, 0, 5000, 10000, 15000), labels = scales::comma(abs(c(-150000, -10000, -5000, 0, 5000, 10000, 15000)))) +\n    scale_fill_brewer(palette = \"Dark2\") + \n    theme_minimal() + \n    theme(legend.position = \"top\") + \n    facet_wrap(~PA, ncol = 3) + \n    ggtitle(\"Comparison of Male and Female Population in SG (June 2022)\") +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    labs(y =\"Age range\", x = \"Population figures\")\n\n#create table for summary statistics\ntbl1 &lt;- data1 %&gt;%\n          group_by(PA, Sex) %&gt;%\n          summarise(sum = sum(Pop), .groups = 'drop')\n\nggp_table &lt;- ggplot() +                             \n  theme_void() +\n  annotate(geom = \"table\",\n           x = 1,\n           y = 1,\n           label = list(tbl1))\n\nggp + ggp_table"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-3.html",
    "href": "Take Home Exercises/Take-Home-Exercise-3.html",
    "title": "Take Home Exercise 03",
    "section": "",
    "text": "The dataset to be examined in this Visual Analytics assignment is taken from Singstat on the Resale Flat prices (based on registration date) in Singapore for the period of Y2022.\nUpon checking the dataset, the following columns are available to be used in the analysis:\n\n\n\n\n\n\n\nVariable Name\nDescription of Variable\n\n\n\n\nmonth\nDatetime (Month) “YYYY-MM” of the associated resale price\n\n\ntown\nArea where the resale flat is located in\n\n\nflat_type\nType of flat eg. 3 room or 4 room\n\n\nblock\nBlock number of the resale flat\n\n\nstreet_name\nStreet where the resale flat is located\n\n\nstorey_range\nRange of floors applicable for the resale price\n\n\nfloor_area_sqm\narea in sqm of the flat\n\n\nflat_model\nIndication of whether flat is ‘Improved’ or ‘New Generation’\n\n\nlease_commence_date\nThe year in which the lease started\n\n\nremaining_lease\nRemaining lease in years and months\n\n\nresale_price\nPrice of the resale flat in SGD\n\n\n\nIn order to use the data provided more effectively, the following cleaning steps and variable conversions were done using Excel first before application in R to extract and apply the variables in the visualization.\n\n\n\n\n\n\n\n\nS/N\nVariable\nTransformation Step\n\n\n\n\n1\nmonth\nSplit the year and the month into 2 new columns for easier reference to the time period ‘month’\n\n\n2\nremaining_lease\nTransformed to months instead of years and months and renamed variable to ‘remaining_lease_months’"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-3.html#a-does-resale-price-have-a-linear-relationship-with-remaining-lease-months",
    "href": "Take Home Exercises/Take-Home-Exercise-3.html#a-does-resale-price-have-a-linear-relationship-with-remaining-lease-months",
    "title": "Take Home Exercise 03",
    "section": "(A) Does resale price have a linear relationship with remaining lease months?",
    "text": "(A) Does resale price have a linear relationship with remaining lease months?\nTo examine this, we apply the visualization for significant test of correlation between the resale flat prices and the remaining lease months variable to see if there is a relationship. Using R, ggscatterstats can be used to obtain the correlation plot between resale flat prices and remaining lease months directly.\n\nggscatterstats(\n  data = resale_flat, \n  x = remaining_lease_months, \n  y = resale_price,\n  marginal = FALSE,\n  xlab = 'Remaining Lease (Months)',\n  ylab = 'Resale Price'\n)"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-3.html#b-is-resale-price-affected-by-the-month-of-the-year",
    "href": "Take Home Exercises/Take-Home-Exercise-3.html#b-is-resale-price-affected-by-the-month-of-the-year",
    "title": "Take Home Exercise 03",
    "section": "(B) Is resale price affected by the month of the year?",
    "text": "(B) Is resale price affected by the month of the year?\nTo answer this question, we first plot multi-ridge plots to determine the resale flat price distribution across town areas to have an idea of how different they could be.\n\nggplot(resale_flat,\n       aes(x = resale_price, y = town, fill =town)) +\n  geom_density_ridges(alpha = 0.5) + \n  theme_ridges() + \n  labs(\"Resale Flat Prices Across Towns over the Year 2022\") + \n  theme(legend.position = \"none\") + \n  labs(x = \"Resale Flat Prices in Y2022\", y = \"Town\") \n\n\n\n\nThis is followed by plotting a stacked bar plot across the months in Y2022 to visualize the distribution of Resale Price according to the town areas.\n\nggplot(resale_flat, \n       aes(x =as.factor(month), resale_price, color = town)) + \n  geom_bar(stat = \"identity\") + \n  labs(x = \"Months of the Year 2022\", y = \"Resale Flat Price\")\n\n\n\n\nFollowing which, to determine if there are significant differences between groups (ie months), we perfrom the oneway ANOVA test using ggbetweenstats for non-parametric (assume unknown and unequal variance).\n\nggbetweenstats(\n  data = resale_flat,\n  x = month, \n  y = resale_price,\n  type = \"np\",\n  messages = FALSE\n)"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-3.html#c-does-the-storey-eg.-higher-vs-lower-floors-matter-and-affect-the-resale-price",
    "href": "Take Home Exercises/Take-Home-Exercise-3.html#c-does-the-storey-eg.-higher-vs-lower-floors-matter-and-affect-the-resale-price",
    "title": "Take Home Exercise 03",
    "section": "(C) Does the storey (eg. higher vs lower floors) matter and affect the resale price?",
    "text": "(C) Does the storey (eg. higher vs lower floors) matter and affect the resale price?\nTo observe the distribution of the prices, a bar plot diagram is used to check the distribution. For this, we apply ggplot's barplot to have an idea of the mean resale price trend across the different storey_ranges.\n\nggplot(resale_flat, \n       aes(x =storey_range, y = resale_price, color = storey_range)) + \n  geom_bar(position = \"dodge\",\n           stat = \"summary\", \n           fun = \"mean\") + \n  labs(x = \"Storey Range\", y = \"Resale Flat Price\")\n\n\n\n\nOneway ANOVA Test was conducted between storey ranges and the resale price using ggbetweenstats.\n\nggbetweenstats(\n  data = resale_flat,\n  x = storey_range, \n  y = resale_price,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\nTo provide visibility about the uncertainty of point estimates for resale price across storey range, we can use ggdist package and specifically stat_pointinterval() to have a sensing of the uncertainty.\n\nresale_flat %&gt;%\n  ggplot(aes(x = storey_range, \n             y = resale_price)) +\n  stat_gradientinterval(\n    fill = \"skyblue\", \n    show.legend = TRUE\n  ) +   #&lt;&lt;\n  labs(\n    title = \"Visualising confidence intervals of mean resale price across storey range\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-3.html#d-can-a-model-of-factors-that-influence-price-be-built",
    "href": "Take Home Exercises/Take-Home-Exercise-3.html#d-can-a-model-of-factors-that-influence-price-be-built",
    "title": "Take Home Exercise 03",
    "section": "(D) Can a model of factors that influence price be built?",
    "text": "(D) Can a model of factors that influence price be built?\nTo examine this, we first apply a multiple linear regression model to see if a model can be constructed using the numerical variables in our data set.\n\nmodel &lt;- lm(resale_price ~ floor_area_sqm + month + lease_commence_date + remaining_lease_months, data = resale_flat)\n\nmodel\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + month + lease_commence_date + \n    remaining_lease_months, data = resale_flat)\n\nCoefficients:\n           (Intercept)          floor_area_sqm                   month  \n            -2.593e+07               4.619e+03               2.443e+03  \n   lease_commence_date  remaining_lease_months  \n             1.339e+04              -8.075e+02  \n\n\nWe check for multi-collinearity as follows and find that both ‘lease_commence_date’ and ‘remaining_lease_months’ have high degree of collinearity and we should re-run the model again while dropping one of these variables\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\nTo complete model diagnostic checks, run check_model on the model to obtain an overall view of diagnostic parameters like Homogeity of Variance and Normality of Residuals:\n\ncheck_model(model)\n\n\n\n\nRe-run of Model with ‘lease_commence_date’ dropped:\n\nmodel_2 &lt;- lm(resale_price ~ floor_area_sqm + month + remaining_lease_months, data = resale_flat)\n\nmodel_2\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + month + remaining_lease_months, \n    data = resale_flat)\n\nCoefficients:\n           (Intercept)          floor_area_sqm                   month  \n             -191680.6                  4609.5                  3488.4  \nremaining_lease_months  \n                 305.3  \n\nsummary(model_2)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + month + remaining_lease_months, \n    data = resale_flat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-256649  -74795  -27172   36097  778194 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -1.917e+05  4.574e+03  -41.91   &lt;2e-16 ***\nfloor_area_sqm          4.610e+03  2.919e+01  157.91   &lt;2e-16 ***\nmonth                   3.488e+03  2.016e+02   17.30   &lt;2e-16 ***\nremaining_lease_months  3.053e+02  3.947e+00   77.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 113400 on 26731 degrees of freedom\nMultiple R-squared:  0.5571,    Adjusted R-squared:  0.5571 \nF-statistic: 1.121e+04 on 3 and 26731 DF,  p-value: &lt; 2.2e-16\n\n\n\nggcoefstats(model_2, output =\"plot\")\n\n\n\n\np-values in the model are significant and the F-value is also large enough to indicate that the model is stable. Plot to visualize the model parameters using ggcoefstats to see where the values lie with respect to the terms."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html",
    "title": "Take Home Exercise 04",
    "section": "",
    "text": "Using visualization techniques learnt in Lesson 6: It’s About Time, appropriate interactive techniques to enhance user experience and data discovery experiences.\nThe focus will be on import and export data for the period of Y2022 to Y2022 and the intention of the visualizations is to make salient any patterns and impact to bilateral trade balance, imports and exports to Singapore post-COVID.\npacman::p_load(tidyverse, gganimate, patchwork, gapminder, readxl, gifski, png, transformr, CGPfunctions, ggthemes, ggHoriPlot, lubridate)\nimports_raw &lt;- read_excel(\"MerchandiseTrade.xlsx\", sheet = \"T1\")\nexports_raw &lt;- read_excel(\"MerchandiseTrade.xlsx\", sheet = \"T2\")"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#data-cleaning",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#data-cleaning",
    "title": "Take Home Exercise 04",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nStep 1. Drop rows which contain irrelevant data from the raw imported data source in separated raw tables since imports and exports are from 2 tabs in the excel file.\n\nimports &lt;- imports_raw[-c(1:8, 129:151),]\nexports &lt;- exports_raw[-c(1:8, 101:123),]\n\nStep 2. Perform initial data cleaning by reshaping the data and renaming variables for both imports and exports table.\n\nimports1 &lt;- as.data.frame(t(imports)) #Transpose rows and columns \nnames(imports1) &lt;- imports1[1,] # Rename Title Rows with row 1 values \nimports1 &lt;- imports1[-1,] #Drop the unneccesary row \nnames(imports1)[1] =\"DateYear\" # Rename Year Month Column \nimports2 &lt;- imports1[, -2] # Drop Unneccessary columns \n\n#Repeat the same steps above for the exports table\nexports1 &lt;- as.data.frame(t(exports))\nnames(exports1) &lt;- exports1[1,] \nexports1 &lt;- exports1[-1,]\nnames(exports1)[1] =\"DateYear\"\nexports2 &lt;- exports1[, -2]\n\nStep 3. Tidy both the Imports and Exports tables using pivot_longer to reshape data.\n\n#Pivot longer for the imports table \nimports3 &lt;- imports2 %&gt;% \n  pivot_longer(\n    cols = !DateYear,\n    names_to = \"Country\", \n    values_to = \"Import_Value\"\n  )\n\n#Multiply Trade Value column by Thousands to get actual value \nimports3$Import_Value&lt;- 1000*as.numeric(imports3$Import_Value)\n\n#Separate columns\nimports_tidy &lt;- imports3 %&gt;% separate(DateYear, c('Year', 'Month')) \nimports_tidy[c('Country', 'X')] &lt;- str_split_fixed(imports_tidy$Country, \" \\\\(\", 2)\n\n# Drop column X\nimports_tidy &lt;- imports_tidy[, -5]\n\n\n#Pivot longer for the exports table \nexports3 &lt;- exports2 %&gt;% \n  pivot_longer(\n    cols = !DateYear,\n    names_to = \"Country\", \n    values_to = \"Export_Value\"\n  )\n\n#Multiply Trade Value column by Thousands to get actual value \nexports3$Export_Value&lt;- 1000*as.numeric(exports3$Export_Value)\n\n#Separate columns\nexports_tidy &lt;- exports3 %&gt;% separate(DateYear, c('Year', 'Month')) \nexports_tidy[c('Country', 'X')] &lt;- str_split_fixed(exports_tidy$Country, \" \\\\(\", 2)\n\n# Drop column X \nexports_tidy &lt;- exports_tidy[, -5] \n\nStep 4. Join both the Exports and Imports tidied tables into 1 overall table called ‘trade’\n\ntrade = merge(x=imports_tidy,y=exports_tidy,by=c(\"Country\", \"Year\", \"Month\"),all=TRUE)\n\n#Creating new column Balance of Trade (BOT) \ntrade$BOT &lt;- trade$Export_Value - trade$Import_Value"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#unveiling-salient-trade-patterns",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#unveiling-salient-trade-patterns",
    "title": "Take Home Exercise 04",
    "section": "Unveiling Salient Trade Patterns",
    "text": "Unveiling Salient Trade Patterns\nThe important countries of interest to be studied are first identified. The basis of selection is taken from the Department of Singstats’s infographic information provided on the major international trade partners that Singapore has.\nThe top 6 countries are: United States, Japan, Mainland China, Australia, Hong Kong, United Kingdom"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#what-are-the-bilateral-trade-patterns-of-singapores-top-6-trading-partner-countries-in-y2022",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#what-are-the-bilateral-trade-patterns-of-singapores-top-6-trading-partner-countries-in-y2022",
    "title": "Take Home Exercise 04",
    "section": "What are the bilateral trade patterns of Singapore’s Top 6 trading partner countries in Y2022?",
    "text": "What are the bilateral trade patterns of Singapore’s Top 6 trading partner countries in Y2022?\nTo visualize last year’s bilateral trade trend for last year, we first visualize using a moving line plot. This will attempt to reveal the current month-by-month changes in exports made and imports from the respective countries.\nStep 1. Extract target countries into a new table and group accordingly to the trade-type (export and import).\n\ntop_6 &lt;- subset(trade, Year == '2022' & Country %in% c('United States', 'Japan', 'Mainland China', 'Australia','Hong Kong', 'United Kingdom'))\n\n# Convert the month name to numbers\ntop_6[[\"Month\"]] &lt;- match(top_6[[\"Month\"]], month.abb)\n\n# Pivot longer for Import and Export Values \ntop_6 &lt;- top_6 %&gt;% \n  pivot_longer(\n    cols = Import_Value:Export_Value,\n    names_to = \"Trade_Type\", \n    values_to = \"Trade_Value\"\n  )\n\nStep 2. Plot moving line plots using gganimate:\n\ntop6_ggplot &lt;- ggplot(top_6, (aes(x = Month, y = Trade_Value, group = Trade_Type, color = Trade_Type))) + \n  geom_line(alpha = 2, show.legend = TRUE) + \n  scale_size(range = c(3,12)) + \n  scale_x_discrete(limits = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\")) +\n  transition_reveal(Month) + \n  facet_wrap(~Country) + \n  labs(title = \"Trade Value Trend in Y2022 by Month\", x = 'Month in Y2022', y = 'Trade Amount') \n\nanimate(top6_ggplot, renderer = gifski_renderer())\n\n\n\n\nFindings:\n\nFrom the visualization, it is observed that Mainland China had one of the highest trade volumes in both exports and imports as compared to the other countries. As such , contrary to Y2020, where United States was at the front leader, China has overtaken as Singapore’s No. 1 trading partner in volume now.\nHong Kong has a noticeable larger trade surplus as compared to the other countries which suggests that demand for SG goods is very high in Hong Kong.\nWith the 2 greater players China and United States, Trade surplus is also not consistent throughout the year and appears to be in deficit for a great part of Y2022."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#observing-import-export-values-over-the-years-for-top-6-countries",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#observing-import-export-values-over-the-years-for-top-6-countries",
    "title": "Take Home Exercise 04",
    "section": "Observing Import & Export Values over the years for Top 6 countries",
    "text": "Observing Import & Export Values over the years for Top 6 countries\nTo display an overall pattern on a year by year basis, we plot another moving line diagram to illustrate the trend of imports and export values for the 6 trading countries.\nStep 1. Create a new table covering data from the years 2020 to 2022 with summed (by year) values for Imports and Exports.\n\n#New table with just import and export values only \ndata3 &lt;- trade[, -6]\n\nsum_trade &lt;- data3 %&gt;% \n    group_by(Country, Year) %&gt;%\n    summarize(sum_import = sum(Import_Value), sum_export = sum(Export_Value))\n\nStep 2. Define the desired datatable for study and plot the moving line plot using gganimate\n\ntop_6_years &lt;- subset(sum_trade, Year %in% c('2020', '2021','2022') & Country %in% c('United States', 'Japan', 'Mainland China', 'Australia','Hong Kong', 'United Kingdom'))\n\n# Convert Year to numeric\ntop_6_years$Year &lt;- as.numeric(top_6_years$Year)\n\n# Pivot longer for Import and Export Values \ntop_6_years &lt;- top_6_years %&gt;% \n  pivot_longer(\n    cols = sum_import: sum_export,\n    names_to = \"Trade_Type\", \n    values_to = \"Trade_Value\"\n  )\n\n\ntop6_yr &lt;- ggplot(top_6_years, (aes(x = Year, y = Trade_Value, group = Trade_Type, color = Trade_Type))) + \n  geom_line(alpha = 2, show.legend = TRUE) + \n  scale_size(range = c(3,12)) + \n  scale_x_discrete(limits = c(2020, 2021, 2022)) +\n  transition_reveal(Year) + \n  facet_wrap(~Country) + \n  labs(title = \"Trade Trends over 2020 to 2022\", y = 'Trade Amount') \n\nanimate(top6_yr, renderer = gifski_renderer())"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#observing-year-period-y2020-to-y2022-trends-of-balance-of-trade-for-key-trade-partners",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#observing-year-period-y2020-to-y2022-trends-of-balance-of-trade-for-key-trade-partners",
    "title": "Take Home Exercise 04",
    "section": "Observing year period (Y2020 to Y2022) trends of Balance of Trade for key trade partners",
    "text": "Observing year period (Y2020 to Y2022) trends of Balance of Trade for key trade partners\nTo visualize this trend, we plot the slope graph to uncover the magnitudes of trade surplus and trade deficit that Singapore experienced over the years with the 6 major trading partners.\nStep 1. Create a new table for the sum of Balance of Trade\n\ndata2 &lt;- trade[, -c(4,5)]\ndata2[[\"Month\"]] &lt;- match(data2[[\"Month\"]], month.abb)\n\nsum_BOT &lt;- data2 %&gt;% \n    group_by(Country, Year) %&gt;%\n    summarize(sum_BOT = sum(BOT))\n\nStep 2. Plot the slope graph using the function newggslopegraph for the period of Y2020 to Y2021 to display the summed up balance of trade on the year level.\n\nsum_BOT %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c('2020', '2021', '2022')) %&gt;%\n  filter(Country %in% c('United States', 'Japan', 'Hong Kong', 'Australia', 'United Kingdom', 'Mainland China'))%&gt;%\n  newggslopegraph(Year, sum_BOT, Country,\n                Title = \"Balance of Trade by Year of Top 6 Trading Countries\",\n                SubTitle = \"Trade Movements from Y2020 to Y2022\",\n                Caption = \"Understanding Impact of COVID on Balance of Trade\")\n\n\n\n\nFindings:\n\nHong Kong has the greatest trade surplus consistently in Y2020 to 2022 as compared to the other 5 major players. As the value appears to be increasing, from Y2020 to Y2021 and sustained thereafter, it suggests that some export recovery to Hong Kong has been attained post-COVID.\nFor countries Japan, United Kingdom and United States however, exports in Y2021 and Y2022 are much lower compared to Y2020 which suggest no export recovery yet. Alternatively, this is also because of increase of imports relative to Y2020 which was the case for both United States and Japan."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#how-does-the-trend-for-balance-of-trade-go-by-the-month-level",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#how-does-the-trend-for-balance-of-trade-go-by-the-month-level",
    "title": "Take Home Exercise 04",
    "section": "How does the trend for Balance of Trade go by the month level?",
    "text": "How does the trend for Balance of Trade go by the month level?\nWhile looking at the year level of balance of trade might reveal some insight, the month level trends of balance of trade would be useful to unveil any particular period specific trends with regards to trade. To show this pattern, the horizon plot will be plotted using geom_horizon function.\nStep 1. Prepare table for study\n\ntop6_horizon &lt;- trade %&gt;% filter(Year %in% c('2020', '2021', '2022'), Country %in% c('United States', 'Hong Kong','United Kingdom', 'Mainland China', 'Australia', 'Japan') )\n\n\n# Combine the Year and Month column\ntop6_horizon$Date &lt;- with(top6_horizon, sprintf(\"%s-%02s\", Month, Year))\ntop6_horizon$Date &lt;- mdy(top6_horizon$Date)\n\nStep 2. Plot the Horizon Plot to unveil clearer the trade balance patterns across the months.\n\ntop6_horizon %&gt;%\n  ggplot() + \n  geom_horizon(aes(x = Date, y = BOT),\n               origin = \"midpoint\",\n               horizonscale =6) + \n  facet_grid(`Country`~.) + \n    theme_few() + \n  scale_fill_hcl(palette = 'RdBu') + \n  theme(panel.spacing.y = unit(0, \"lines\"), strip.text.y = element_text(\n    size = 7, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size =7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n  )+ \n  scale_x_date(expand = c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") + \n  ggtitle('Trade Balance (Deficit) of 6 Key Trading Countries (Y2020 to Y2022)')\n\n\n\n\nFindings:\n\nOver the months in the period of Y2020 to Y2022, trade surplus was relatively consistent for both Australia and Hong Kong since the middle of the COVID period. This suggests that commodities exported out from Singapore during the second half of COVID were in high demand in both Australia and Hong Kong.\nHowever, Trade deficit was persistent for United Kingdom and also starting from the middle of Y2022 onwards became prominent for other countries like China, United States and Japan as well."
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#ranking-of-bilateral-trade-exports",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#ranking-of-bilateral-trade-exports",
    "title": "Take Home Exercise 04",
    "section": "Ranking of Bilateral Trade (Exports)",
    "text": "Ranking of Bilateral Trade (Exports)\nTo show the trend and pattern of changes in rankings of countries in terms of export values, we plot an animated bar chart for 14 selected countries (including the 6 that were previously explored) to see if there is any other pattern that can be unveiled. These 14 countries were highlighted for being major trading partners in either Y2020 or Y2022 or both.\n\ndata3 &lt;- trade[, -6]\n\nsum_Exim &lt;- data3 %&gt;% \n    group_by(Country, Year) %&gt;%\n    summarize(sum_export = sum(Export_Value), sum_import = sum(Import_Value))\n\n\nsum_Exim &lt;- sum_Exim %&gt;%\n  filter(Country %in% c('United States', 'Hong Kong','United Kingdom', 'Mainland China', 'Australia', 'Japan', 'Switzerland', 'Ireland','India', 'Malaysia', 'Republic Of Korea', 'Thailand', 'Indonesia', 'Taiwan') & Year %in% c('2018', '2019','2020','2021','2022')) %&gt;% \n  group_by(Year) %&gt;%\n  #Rank Export values by year\n  mutate(rank = rank(-sum_export),\n         Export_rel = sum_export/sum_export[rank == 1],\n         Export_lbl = paste0(\"$ \", round(sum_export, 4))) %&gt;%\n  group_by(Country) %&gt;%\n  ungroup()\n\nCreate a static plot graph for Exports:\n\nexport.static &lt;- ggplot(sum_Exim, aes(rank, group = Country,\n                fill = as.factor(Country), color = as.factor(Country))) +\n  geom_tile(aes(y = sum_export/2,\n                height = sum_export,\n                width = 0.9), alpha = 0.8, color = NA) +\n  geom_text(aes(y = 0, label = paste(Country, \" \")), vjust = 0.2, hjust = 1, size = 5) +\n  geom_text(aes(y = sum_export, label =  Export_lbl, hjust = 0), size = 6) +\n  coord_flip(clip = \"off\", expand = FALSE) +\n  scale_y_continuous(labels = scales::comma) +\n  scale_x_reverse() +\n  guides(color = FALSE, fill = FALSE) +\n  theme(axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\",\n        panel.background = element_blank(),\n        panel.border = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_line(size = 0.1, color = \"grey\"),\n        panel.grid.minor.x = element_line(size = 0.1, color = \"grey\"),\n        plot.title = element_text(size = 25),\n        plot.subtitle = element_text(size=18, face = \"italic\", color = \"grey\",  hjust = 0.5, vjust = -1),\n        plot.background = element_blank(),\n        plot.margin = margin(4, 4, 4, 4, \"cm\"))\n\nUse the transition_states() function from the gganimate package to allow the changes in the ranking\n\nanim &lt;- export.static + \n  transition_states(Year, transition_length = 4, state_length = 1) +\n  view_follow(fixed_x = TRUE)  +\n  labs(title = 'Export Values for 14 identified trading partners of Singapore: {closest_state}',\n       subtitle  = \"Values reported up to 4 significant figures\")\n\n\nanimate(anim, 200, fps = 20, width = 1200, height = 1000, \n        renderer = gifski_renderer())"
  },
  {
    "objectID": "Take Home Exercises/Take-Home-Exercise-4.html#ranking-of-bilateral-trade-imports",
    "href": "Take Home Exercises/Take-Home-Exercise-4.html#ranking-of-bilateral-trade-imports",
    "title": "Take Home Exercise 04",
    "section": "Ranking of Bilateral Trade (Imports)",
    "text": "Ranking of Bilateral Trade (Imports)\nSimilarly, we plot the same animated bar chart graph to display the ranking for Import Values as well.\n\nsum_Import &lt;- sum_Exim %&gt;%\n  filter(Country %in% c('United States', 'Hong Kong','United Kingdom', 'Mainland China', 'Australia', 'Japan', 'Switzerland', 'Ireland','India', 'Malaysia', 'Republic Of Korea', 'Thailand', 'Indonesia', 'Taiwan') & Year %in% c('2018', '2019','2020','2021','2022')) %&gt;% \n  group_by(Year) %&gt;%\n  #Rank Export values by year\n  mutate(rank = rank(-sum_import),\n         Import_rel = sum_import/sum_import[rank == 1],\n         Import_lbl = paste0(\"$ \", round(sum_import, 4))) %&gt;%\n  group_by(Country) %&gt;%\n  ungroup()\n\nCreate the static plot for Import values\n\nimport.static &lt;- ggplot(sum_Import, aes(rank, group = Country,\n                fill = as.factor(Country), color = as.factor(Country))) +\n  geom_tile(aes(y = sum_import/2,\n                height = sum_import,\n                width = 0.9), alpha = 0.8, color = NA) +\n  geom_text(aes(y = 0, label = paste(Country, \" \")), vjust = 0.2, hjust = 1, size = 5) +\n  geom_text(aes(y = sum_import, label = Import_lbl, hjust = 0), size = 6) +\n  coord_flip(clip = \"off\", expand = FALSE) +\n  scale_y_continuous(labels = scales::comma) +\n  scale_x_reverse() +\n  guides(color = FALSE, fill = FALSE) +\n  theme(axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\",\n        panel.background = element_blank(),\n        panel.border = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_line(size = 0.1, color = \"grey\"),\n        panel.grid.minor.x = element_line(size = 0.1, color = \"grey\"),\n        plot.title = element_text(size = 25),\n        plot.subtitle = element_text(size=18, face = \"italic\", color = \"grey\",  hjust = 0.5, vjust = -1),\n        plot.background = element_blank(),\n        plot.margin = margin(4, 4, 4, 4, \"cm\"))\n\n\nanim_import &lt;- import.static + \n  transition_states(Year, transition_length = 4, state_length = 1) +\n  view_follow(fixed_x = TRUE)  +\n  labs(title = 'Import Values for 14 identified trading partners of Singapore: {closest_state}',\n       subtitle  = \"Values reported up to 4 significant figures\")\n\n\nanimate(anim_import, 200, fps = 20, width = 1200, height = 1000, \n        renderer = gifski_renderer())\n\n\n\n\nFindings:\n\nBased on the Export and Import rankings graph, it is observed that Malaysia has overtaken United States to be the 2nd largest trading partner in terms of exports and imports for Singapore. This seems to be an impact of COVID since due to restriction measures, overseas trade for products and services were very limited by geo-distances.\nWhile imports from Japan have been consistently high over the years, imports from Korea have also increased, overtaking even Indonesia. This could also be an effect from a greater interest in Korean culture and higher demand its related products and services."
  },
  {
    "objectID": "take-home-exercise-1.html",
    "href": "take-home-exercise-1.html",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Task Objective:\nData Source:\nBasis of selection for the 9 Planning areas:"
  },
  {
    "objectID": "take-home-exercise-1.html#data-preparation",
    "href": "take-home-exercise-1.html#data-preparation",
    "title": "Take-Home Exercise 1",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n\n\n\n\n\n\n\nNo.\nDescription of Step\n\n\n\n\n\n1\nLoad data file\n\nConnect a new data source to Tableau by loading the csv file ‘CSVrespopagesextod2022’ into Tableau prep builders.\nAfter loading the file, the preview of the data would show up according to figure right.\n\nThe following columns should be view-able with the corresponding definitions:\n\nPA : Planning Area, SZ: Subzone, AG: Age group range, Sex, TOD: Type of Development, Pop: Population figure, Time: 2022\n*Since slice of data was taken for June 2022, ‘Time’ column will display the same value throughout the dataset.\n\n\n\n\n2\nData treatment (‘Sex’ column)\n\nSince Males and Females are in the same column, create 2 new columns to clearly identify population numbers for females and males separately.\nRight-click the column ‘Sex’ and locate the command ‘Create Calculated Field’\nCreate a new column named ‘Male’ with the following calculation inserted: see Figure 3. This will identify a new column for populations numbers of Males only.\nRepeat the same calculation to create a second column named ‘Female’\nAt the end of this step, you should have 2 new calculated columns created that should look like Figure 5."
  },
  {
    "objectID": "take-home-exercise-1.html#creating-the-age-gender-pyramid-in-a-trellis-view",
    "href": "take-home-exercise-1.html#creating-the-age-gender-pyramid-in-a-trellis-view",
    "title": "Take-Home Exercise 1",
    "section": "Creating the Age-Gender Pyramid in a Trellis View",
    "text": "Creating the Age-Gender Pyramid in a Trellis View\n\n\n\n\n\n\n\n\nNo.\nDescription of Step\n\n\n\n\n\n1\n\nOpen up a new sheet & rename it to ‘Age-Gender Pyramid Trellis’\nDrag the variables ‘PA’ to Columns and ‘AG’ to Rows respectively to produce a table that displays all the 55 PA as column headers and age groups as rows\n\n\n\n\n2\n\nAdd the data that is to be displayed\nDrag the calculated columns ‘Male’ and ‘Female’ to Columns respectively. The Sums of populations for both Male and Female are reported immediately in the form of a bar chart.\nSince ‘Male’ and ‘Female’ population breakdown is reported correspondingly for each Planning area (see example on the right for Ang Mo Kio)\n\n\n\n\n\n3\nSelection of 9 Planning Areas to display\n\nTo limit the 9 areas to display, drag ‘PA’ to the Filters box\nSelect the following 9 Planning Areas in the list to report. As the pre-selection has been set to report all the Planning Areas, click ‘None’ first to de-select all options before selecting the 9.\n\nAng Mo Kio\nBukit Merah\nBukit Timah\nHougang\nJurong East\nKallang\nPasir Ris\nSengkang\n\nThe result should show only the 9 selected planning areas as shown on the right.\n\n\n\n\n\n\n4\nFormatting of the Trellis Chart (Color)\n\nCreate color distinction between ‘Male’ and ‘Female’ populations by doing the following:\n\nUnder the Marks section, navigate to SUM(Male) and change the color of the marks to green. Repeat this step for SUM(Female) to change the color of the marks to pink.\n\n\n\n\n\n\n5\nFormatting of the Trellis Chart (sort AG axis)\n\nSort the y-axis to report the Age groups in descending order. Right-click the AG axis and sort in descending order\n\n\n\n\n6\nFormatting of the Trellis Chart (Pyramid effect)\n\nTo create the pyramid effect, we have the reverse the x-axis of ‘Male’\nRight-click ‘Male’ at the x-axis and click ‘Edit Axis’. Under ‘Scale’, select the ‘Reversed’ option.\nThe final result should cause the pyramid effect (see example for Bukit Merah)\n\n\n\n\n\n7\nFormatting of the Trellis Chart (Enhance visualization)\n\nClick ‘Fit Height’ above the column shelf to re-size the trellis chart to fit the height of the dashboard\nHide row & column header field because the title would already cover this\nRename the Title accordingly to ‘SG Population Age- Gender distribution over 9 Planning Areas (June 2022)’\nUnder ‘Format Lines’ click none under ‘Grid Lines’ for a cleaner look\nFormat and change the size of the PA Font to 14 , in boldface by right-clicking ‘Format’ of PA and making the changes in the Default panel\nLikewise, do the same for the Age-group y-axis by changing the Default font to size 12 and boldface\n\n\n\n\n\n\n\n\n8\nAdding labels to the diagrams\n\nAssuming target audience of the dashboard is on a working level and requires level of detail to each label, add labels for both ‘Male’ and ‘Female’ by dragging both variables to Marks as a Label\nAdjust the color of the font as necessary with format and you should be able to get the figure on the right (example for Bukit Timah)"
  }
]